#!/usr/bin/env python3
"""
Script para testar normalizaÃ§Ã£o de headers e comparar com BigQuery schema
"""
import unicodedata
import re

# Headers reais das abas
PIPELINE_HEADERS = [
    "Run ID", "Oportunidade", "Conta", "Perfil", "Produtos", "Vendedor", "Gross", "Net",
    "Fase Atual", "Forecast SF", "Fiscal Q", "Data Prevista", "Ciclo (dias)", "Dias Funil",
    "Atividades", "Atividades (Peso)", "Mix Atividades", "Idle (Dias)", "Qualidade Engajamento",
    "Forecast IA", "ConfianÃ§a (%)", "Motivo ConfianÃ§a", "MEDDIC Score", "MEDDIC Gaps",
    "MEDDIC EvidÃªncias", "BANT Score", "BANT Gaps", "BANT EvidÃªncias", "Justificativa IA",
    "Regras Aplicadas", "IncoerÃªncia Detectada", "Perguntas de Auditoria IA", "Flags de Risco",
    "Gaps Identificados", "CÃ³d AÃ§Ã£o", "AÃ§Ã£o Sugerida", "Risco Principal", "# Total MudanÃ§as",
    "# MudanÃ§as CrÃ­ticas", "MudanÃ§as Close Date", "MudanÃ§as Stage", "MudanÃ§as Valor",
    "ğŸš¨ Anomalias Detectadas", "Velocity PrediÃ§Ã£o", "Velocity Detalhes", "TerritÃ³rio Correto?",
    "Vendedor Designado", "Estado/Cidade Detectado", "Fonte DetecÃ§Ã£o", "CalendÃ¡rio FaturaÃ§Ã£o",
    "Valor Reconhecido Q1", "Valor Reconhecido Q2", "Valor Reconhecido Q3", "Valor Reconhecido Q4",
    "ğŸ• Ãšltima AtualizaÃ§Ã£o"
]

WON_HEADERS = [
    "Run ID", "Oportunidade", "Conta", "Perfil Cliente", "Vendedor", "Gross", "Net",
    "PortfÃ³lio", "Segmento", "FamÃ­lia Produto", "Status", "Fiscal Q", "Data Fechamento",
    "Ciclo (dias)", "Produtos", "ğŸ“ Resumo AnÃ¡lise", "ğŸ¯ Causa Raiz", "âœ¨ Fatores Sucesso",
    "Tipo Resultado", "Qualidade Engajamento", "GestÃ£o Oportunidade", "-", "ğŸ’¡ LiÃ§Ãµes Aprendidas",
    "# Atividades", "Ativ. 7d", "Ativ. 30d", "DistribuiÃ§Ã£o Tipos", "PerÃ­odo Pico",
    "CadÃªncia MÃ©dia (dias)", "# Total MudanÃ§as", "# MudanÃ§as CrÃ­ticas", "MudanÃ§as Close Date",
    "MudanÃ§as Stage", "MudanÃ§as Valor", "Campos + Alterados", "PadrÃ£o MudanÃ§as",
    "Freq. MudanÃ§as", "# Editores", "ğŸ·ï¸ Labels", "ğŸ• Ãšltima AtualizaÃ§Ã£o"
]

LOST_HEADERS = [
    "Run ID", "Oportunidade", "Conta", "Perfil Cliente", "Vendedor", "Gross", "Net",
    "PortfÃ³lio", "Segmento", "FamÃ­lia Produto", "Status", "Fiscal Q", "Data Fechamento",
    "Ciclo (dias)", "Produtos", "ğŸ“ Resumo AnÃ¡lise", "ğŸ¯ Causa Raiz", "âš ï¸ Causas SecundÃ¡rias",
    "Tipo Resultado", "EvitÃ¡vel?", "ğŸš¨ Sinais Alerta", "Momento CrÃ­tico", "ğŸ’¡ LiÃ§Ãµes Aprendidas",
    "# Atividades", "Ativ. 7d", "Ativ. 30d", "DistribuiÃ§Ã£o Tipos", "PerÃ­odo Pico",
    "CadÃªncia MÃ©dia (dias)", "# Total MudanÃ§as", "# MudanÃ§as CrÃ­ticas", "MudanÃ§as Close Date",
    "MudanÃ§as Stage", "MudanÃ§as Valor", "Campos + Alterados", "PadrÃ£o MudanÃ§as",
    "Freq. MudanÃ§as", "# Editores", "ğŸ·ï¸ Labels", "ğŸ• Ãšltima AtualizaÃ§Ã£o"
]

SALES_SPEC_HEADERS = [
    "Account Name", "Perfil", "Opportunity Name", "Meses Fat.", "GTM 2026",
    "Booking Total ($)Gross", "Booking Total ($) Net", "Status", "Vendedor", "Status",
    "Billing Quarter ($)", "Billing Quarter ($)", "Closed Date"
]

def normalize_header(header: str) -> str:
    """Normaliza header seguindo a mesma lÃ³gica do Apps Script"""
    normalized = header.strip()
    
    # Caso especial: campo vazio ou sÃ³ sÃ­mbolos
    if not normalized or normalized in ['-', '_', '.', '#']:
        return ''
    
    # Remover emojis
    normalized = re.sub(
        r'[\U0001F300-\U0001F9FF]|[\U00002600-\U000026FF]|[\U00002700-\U000027BF]|'
        r'[\U0001F000-\U0001F6FF]|[\U0001F900-\U0001F9FF]|[\U0001FA00-\U0001FAFF]',
        '', normalized
    )
    normalized = normalized.strip()
    
    # Remover acentos
    normalized = ''.join(
        c for c in unicodedata.normalize('NFD', normalized)
        if unicodedata.category(c) != 'Mn'
    )
    
    # Remover caracteres especiais (mantÃ©m apenas letras, nÃºmeros, espaÃ§os, underscores e hÃ­fens)
    normalized = re.sub(r'[^a-zA-Z0-9\s_-]', '', normalized)
    
    # Substituir espaÃ§os por underscores
    normalized = re.sub(r'\s+', '_', normalized)
    
    # Remover underscores duplicados
    normalized = re.sub(r'_+', '_', normalized)
    
    # Remover underscores no inÃ­cio e fim
    normalized = normalized.strip('_')
    
    return normalized

def test_normalization(headers, table_name):
    """Testa normalizaÃ§Ã£o de headers"""
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ {table_name}")
    print(f"{'='*80}")
    
    normalized_headers = []
    for i, header in enumerate(headers, 1):
        normalized = normalize_header(header)
        if normalized:  # Pular headers vazios
            normalized_headers.append(normalized)
            print(f"{i:2}. {header:40} â†’ {normalized}")
        else:
            print(f"{i:2}. {header:40} â†’ [VAZIO - SERÃ IGNORADO]")
    
    print(f"\nâœ… Total de colunas: {len(normalized_headers)}")
    
    # Detectar duplicatas
    duplicates = {}
    for h in normalized_headers:
        duplicates[h] = duplicates.get(h, 0) + 1
    
    dupes = [(k, v) for k, v in duplicates.items() if v > 1]
    if dupes:
        print(f"\nâš ï¸  ATENÃ‡ÃƒO: Headers duplicados detectados:")
        for header, count in dupes:
            print(f"   - {header}: {count}x")
    
    return normalized_headers

if __name__ == "__main__":
    print("ğŸ” Testando normalizaÃ§Ã£o de headers para BigQuery\n")
    
    pipeline_normalized = test_normalization(PIPELINE_HEADERS, "ğŸ¯ Pipeline (AnÃ¡lise Forecast IA)")
    won_normalized = test_normalization(WON_HEADERS, "ğŸ“ˆ Closed Deals Won (AnÃ¡lise Ganhas)")
    lost_normalized = test_normalization(LOST_HEADERS, "ğŸ“‰ Closed Deals Lost (AnÃ¡lise Perdidas)")
    sales_normalized = test_normalization(SALES_SPEC_HEADERS, "ğŸ“Š Sales Specialist")
    
    print("\n" + "="*80)
    print("ğŸ“Š RESUMO")
    print("="*80)
    print(f"Pipeline:       {len(pipeline_normalized)} colunas")
    print(f"Won:            {len(won_normalized)} colunas")
    print(f"Lost:           {len(lost_normalized)} colunas")
    print(f"Sales Spec:     {len(sales_normalized)} colunas")
    print("\nâœ… NormalizaÃ§Ã£o testada com sucesso!")
