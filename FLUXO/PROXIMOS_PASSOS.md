# ğŸš€ PrÃ³ximos Passos - Roadmap de ImplementaÃ§Ã£o

**Status Atual**: âœ… Google Sheets â†” BigQuery operacional | ğŸ”§ Cloud Run + Dashboard pendentes

---

## ğŸ“‹ Sprint 1: Treinar Modelos BQML (Prioridade ALTA)

### **Objetivo**: Treinar os 6 modelos de Machine Learning no BigQuery

### **Tarefas**:

#### 1. Preparar ambiente BQML
```bash
# Verificar se dataset existe
bq ls operaciones-br:sales_intelligence

# Verificar dados carregados
bq query --use_legacy_sql=false \
"SELECT 'pipeline' as table, COUNT(*) as rows FROM \`operaciones-br.sales_intelligence.pipeline\`
UNION ALL
SELECT 'won', COUNT(*) FROM \`operaciones-br.sales_intelligence.closed_deals_won\`
UNION ALL
SELECT 'lost', COUNT(*) FROM \`operaciones-br.sales_intelligence.closed_deals_lost\`"
```
- [ ] Validar 2,864 registros carregados
- [ ] Conferir schemas das tabelas
- [ ] Verificar permissÃµes BQML

#### 2. Executar treinamento dos modelos
```bash
cd /workspaces/playbook/bigquery

# Executar script de deploy
./deploy_ml.sh
```
**Modelos a treinar**:
- [ ] `forecast_ia_model` - Prever win/loss (Logistic Regression)
- [ ] `classificador_perda` - Classificar perdas evitÃ¡veis (Logistic Regression)
- [ ] `risco_abandono` - Detectar deals em risco (Boosted Tree)
- [ ] `proxima_acao` - Recomendar aÃ§Ãµes (Classifier)
- [ ] `prioridade_deal` - Ranquear por valor (Linear Regression)
- [ ] `performance_vendedor` - Avaliar vendedores (Boosted Tree)

**Tempo estimado**: 20-40 minutos por modelo

#### 3. Validar acurÃ¡cia dos modelos
```sql
-- Avaliar modelo forecast_ia_model
SELECT
  *
FROM
  ML.EVALUATE(MODEL `operaciones-br.sales_intelligence.forecast_ia_model`,
    (SELECT * FROM `operaciones-br.sales_intelligence.closed_deals_won` LIMIT 100)
  );
```
- [ ] Verificar accuracy > 80%
- [ ] Analisar confusion matrix
- [ ] Documentar resultados em `ML_MODELS_README.md`

#### 4. Testar prediÃ§Ãµes
```sql
-- Teste de prediÃ§Ã£o no pipeline ativo
SELECT
  Oportunidade,
  predicted_outcome,
  predicted_outcome_probs
FROM
  ML.PREDICT(MODEL `operaciones-br.sales_intelligence.forecast_ia_model`,
    (SELECT * FROM `operaciones-br.sales_intelligence.pipeline` LIMIT 10)
  );
```
- [ ] Executar 10 prediÃ§Ãµes de teste
- [ ] Validar formato do output
- [ ] Salvar exemplos de resposta

**CritÃ©rios de Sucesso**:
- âœ… 6 modelos treinados sem erros
- âœ… Accuracy mÃ©dia > 80%
- âœ… Tempo de inferÃªncia < 2s

**DuraÃ§Ã£o**: 2-3 horas

---

## ğŸŒ Sprint 2: Deploy Cloud Run API (Prioridade ALTA)

### **Objetivo**: Fazer deploy da API REST no Google Cloud Run

### **Tarefas**:

#### 1. Preparar ambiente Cloud Run
```bash
cd /workspaces/playbook/cloud-function

# Instalar dependÃªncias localmente
pip install -r requirements.txt

# Testar local
python test_local.py
```
- [ ] Validar requirements.txt
- [ ] Testar imports
- [ ] Verificar autenticaÃ§Ã£o BigQuery

#### 2. Configurar Google Cloud
```bash
# Login no Google Cloud
gcloud auth login

# Configurar projeto
gcloud config set project operaciones-br

# Habilitar APIs necessÃ¡rias
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
```
- [ ] AutenticaÃ§Ã£o configurada
- [ ] Projeto selecionado
- [ ] APIs habilitadas

#### 3. Deploy da aplicaÃ§Ã£o
```bash
# Deploy para Cloud Run
./deploy.sh

# Ou manualmente:
gcloud run deploy sales-intelligence-api \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --max-instances 10
```
- [ ] Build concluÃ­do sem erros
- [ ] ServiÃ§o deployado
- [ ] URL pÃºblica gerada

**URL esperada**: `https://sales-intelligence-api-[hash]-uc.a.run.app`

#### 4. Testar endpoints
```bash
# Testar endpoint /forecast
curl -X POST https://sales-intelligence-api-[hash]-uc.a.run.app/forecast \
  -H "Content-Type: application/json" \
  -d '{
    "oportunidade": "TEST-001",
    "gross": 500000,
    "net": 200000,
    "ciclo_dias": 45,
    "vendedor": "Test User"
  }'

# Testar endpoint /metrics
curl https://sales-intelligence-api-[hash]-uc.a.run.app/metrics
```
- [ ] `/forecast` retorna JSON vÃ¡lido
- [ ] `/risk` funciona
- [ ] `/actions` funciona
- [ ] `/metrics` retorna KPIs

#### 5. Configurar CORS
```python
# main.py
from flask_cors import CORS

app = Flask(__name__)
CORS(app, origins=['https://xerticaai.github.io'])
```
- [ ] CORS habilitado
- [ ] Dashboard pode fazer requests
- [ ] Preflight OPTIONS tratado

**CritÃ©rios de Sucesso**:
- âœ… API deployada e acessÃ­vel
- âœ… Todos os endpoints respondendo
- âœ… Tempo de resposta < 2s
- âœ… CORS configurado

**DuraÃ§Ã£o**: 1-2 horas

---

## ğŸ¨ Sprint 3: Integrar Dashboard HTML (Prioridade MÃ‰DIA)

### **Objetivo**: Conectar dashboard ao Cloud Run e adicionar visualizaÃ§Ãµes

### **Tarefas**:

#### 1. Atualizar index.html com URL da API
```javascript
// public/index.html
const API_URL = 'https://sales-intelligence-api-[hash]-uc.a.run.app';

async function loadDashboard() {
  // Carregar mÃ©tricas
  const metrics = await fetch(`${API_URL}/metrics`).then(r => r.json());
  updateKPIs(metrics);
  
  // Carregar forecast
  const forecast = await fetch(`${API_URL}/forecast`, {
    method: 'POST',
    body: JSON.stringify({ ... })
  }).then(r => r.json());
  updateForecast(forecast);
}
```
- [ ] Substituir URL placeholder
- [ ] Testar fetch local
- [ ] Tratar erros de rede

#### 2. Implementar funÃ§Ãµes de visualizaÃ§Ã£o
```javascript
function updateKPIs(metrics) {
  document.getElementById('pipeline-value').textContent = 
    formatCurrency(metrics.pipeline.total_gross);
  // ... more KPIs
}

function updateForecast(forecast) {
  const chart = new Chart(ctx, {
    type: 'bar',
    data: { ... }
  });
}
```
- [ ] KPIs principal (4 cards)
- [ ] Tabela de oportunidades
- [ ] GrÃ¡fico de pipeline por quarter
- [ ] Alertas crÃ­ticos

#### 3. Adicionar Chart.js para grÃ¡ficos
```html
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
```
**GrÃ¡ficos necessÃ¡rios**:
- [ ] Pipeline por Fiscal Quarter (bar chart)
- [ ] Win Rate trend (line chart)
- [ ] Top Vendedores (horizontal bar)
- [ ] Segmento mix (donut chart)

#### 4. Implementar refresh automÃ¡tico
```javascript
// Atualizar a cada 5 minutos
setInterval(() => {
  loadDashboard();
}, 5 * 60 * 1000);
```
- [ ] Auto-refresh configurado
- [ ] Loading indicators
- [ ] Timestamp "Ãšltima atualizaÃ§Ã£o"

#### 5. EstilizaÃ§Ã£o e responsividade
```css
/* Adicionar CSS responsivo */
@media (max-width: 768px) {
  .kpi-card {
    width: 100%;
  }
}
```
- [ ] Desktop (>1024px)
- [ ] Tablet (768-1024px)
- [ ] Mobile (< 768px)

**CritÃ©rios de Sucesso**:
- âœ… Dashboard carrega dados da API
- âœ… GrÃ¡ficos renderizados
- âœ… Responsivo em 3 breakpoints
- âœ… Auto-refresh funciona

**DuraÃ§Ã£o**: 2-3 horas

---

## âœ… Sprint 4: ValidaÃ§Ã£o End-to-End (Prioridade ALTA)

### **Objetivo**: Testar fluxo completo e documentar

### **Tarefas**:

#### 1. Teste manual do fluxo completo
```
1. Modificar dados no Google Sheets
   â””â”€ Adicionar 1 deal no Pipeline

2. Executar sync manual
   â””â”€ Apps Script > syncToBigQueryScheduled()

3. Validar no BigQuery
   â””â”€ Query: SELECT COUNT(*) FROM pipeline
   â””â”€ Esperado: 269 records (268 + 1)

4. Aguardar Cloud Run atualizar
   â””â”€ Cache pode levar atÃ© 5min

5. Verificar Dashboard
   â””â”€ Abrir index.html
   â””â”€ Confirmar novo deal aparece
```
- [ ] Teste de adiÃ§Ã£o de deal
- [ ] Teste de modificaÃ§Ã£o de deal
- [ ] Teste de exclusÃ£o de deal
- [ ] Validar propagaÃ§Ã£o de mudanÃ§as

#### 2. Testes de performance
```bash
# Load test no Cloud Run
ab -n 100 -c 10 https://sales-intelligence-api-[hash]-uc.a.run.app/metrics

# Verificar response time < 2s
```
- [ ] 100 requests concorrentes
- [ ] P95 < 2s
- [ ] Zero erros 5xx

#### 3. Testes de error handling
```javascript
// Simular API offline
// Verificar se dashboard exibe mensagem de erro
```
- [ ] API offline â†’ erro amigÃ¡vel
- [ ] Timeout â†’ retry automÃ¡tico
- [ ] 400/500 â†’ log e notificaÃ§Ã£o

#### 4. DocumentaÃ§Ã£o final
```bash
# Atualizar READMEs
cd /workspaces/playbook/FLUXO
# Adicionar screenshots
# Documentar URLs finais
# Criar guia de troubleshooting
```
- [ ] README.md atualizado
- [ ] Screenshots adicionados
- [ ] URLs documentadas
- [ ] Guia de troubleshooting criado

**CritÃ©rios de Sucesso**:
- âœ… Fluxo completo funciona sem intervenÃ§Ã£o manual
- âœ… Performance dentro do esperado
- âœ… Errors tratados gracefully
- âœ… DocumentaÃ§Ã£o completa

**DuraÃ§Ã£o**: 2 horas

---

## ğŸ”§ Sprint 5: Melhorias e OtimizaÃ§Ãµes (Prioridade BAIXA)

### **Objetivo**: Refinar sistema e adicionar features extras

### **Tarefas Opcionais**:

#### 1. Cache na API
```python
from flask_caching import Cache

cache = Cache(app, config={'CACHE_TYPE': 'simple'})

@app.route('/metrics')
@cache.cached(timeout=300)  # 5min cache
def get_metrics():
    # ...
```
- [ ] Cache de 5min em `/metrics`
- [ ] Invalidar cache em sync

#### 2. NotificaÃ§Ãµes de alertas
```javascript
// Dashboard: enviar notificaÃ§Ã£o para Slack
if (criticalDeals.length > 10) {
  sendSlackAlert('ğŸš¨ 10+ deals crÃ­ticos!');
}
```
- [ ] IntegraÃ§Ã£o Slack webhook
- [ ] Alertas configurÃ¡veis

#### 3. ExportaÃ§Ã£o de relatÃ³rios
```javascript
// BotÃ£o "Download CSV"
function exportToCSV(data) {
  const csv = convertToCSV(data);
  downloadFile(csv, 'pipeline_report.csv');
}
```
- [ ] Export CSV
- [ ] Export PDF (opcional)

#### 4. HistÃ³rico de prediÃ§Ãµes
```sql
-- Salvar prediÃ§Ãµes para anÃ¡lise posterior
CREATE TABLE `sales_intelligence.prediction_history` AS
SELECT
  CURRENT_TIMESTAMP() as prediction_time,
  *
FROM ML.PREDICT(...)
```
- [ ] Tabela de histÃ³rico
- [ ] Dashboard de acurÃ¡cia

**DuraÃ§Ã£o**: Conforme necessÃ¡rio

---

## ğŸ“… Timeline Sugerido

```
Semana 1:
â”œâ”€ Treinar modelos BQML (Sprint 1)           2-3h
â”œâ”€ Deploy Cloud Run (Sprint 2)               1-2h
â””â”€ Integrar Dashboard (Sprint 3 parcial)     1h

Semana 2:
â”œâ”€ Finalizar Dashboard (Sprint 3)            2h
â”œâ”€ ValidaÃ§Ã£o E2E (Sprint 4)                  2h
â””â”€ DocumentaÃ§Ã£o e ajustes                    1h

Semana 3+ (opcional):
â””â”€ Melhorias (Sprint 5)                      Conforme demanda
```

**Total estimado**: 9-12 horas de trabalho

---

## ğŸ¯ Checklist Final

Antes de considerar o projeto **COMPLETO**, validar:

- [ ] âœ… Google Sheets sincroniza com BigQuery sem erros
- [ ] ğŸ¤– 6 modelos BQML treinados e validados (>80% accuracy)
- [ ] ğŸŒ Cloud Run API deployada e respondendo
- [ ] ğŸ¨ Dashboard HTML conectado e funcional
- [ ] âš¡ Performance E2E < 2s
- [ ] ğŸ“ DocumentaÃ§Ã£o completa no `/FLUXO/`
- [ ] ğŸš¨ Error handling implementado
- [ ] ğŸ“Š Monitoramento configurado
- [ ] ğŸ” SeguranÃ§a validada (CORS, IAM, etc)
- [ ] âœ… Testes E2E passando

---

## ğŸ†˜ Troubleshooting

### Problema: Modelos BQML nÃ£o treinam
```bash
# Verificar quota
bq show --format=prettyjson --project_id=operaciones-br

# Verificar dados
bq query --use_legacy_sql=false \
  "SELECT COUNT(*) FROM \`operaciones-br.sales_intelligence.closed_deals_won\`"
```
**SoluÃ§Ã£o**: MÃ­nimo 100 registros por modelo

### Problema: Cloud Run retorna 503
```bash
# Verificar logs
gcloud run services logs read sales-intelligence-api --limit=20
```
**SoluÃ§Ã£o**: Aumentar timeout ou memory

### Problema: Dashboard nÃ£o carrega dados
```javascript
// Abrir DevTools (F12) e verificar Console
// Procurar erros CORS ou network
```
**SoluÃ§Ã£o**: Verificar CORS no Cloud Run

---

**PrÃ³xima aÃ§Ã£o sugerida**: Iniciar **Sprint 1** - Treinar Modelos BQML ğŸš€

**Criado em**: 06/02/2026  
**Ãšltima atualizaÃ§Ã£o**: 06/02/2026
