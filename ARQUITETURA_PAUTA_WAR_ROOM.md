# üèóÔ∏è ARQUITETURA: PAUTA SEMANAL + WAR ROOM (APRESENTA√á√ÉO SEMANAL)

**Projeto:** Sales Intelligence Dashboard  
**Stack:** BigQuery + Cloud Run (FastAPI) + Frontend Vanilla JS  
**RAG:** Vertex AI Text Embeddings (768d) em `deal_embeddings`  
**Data:** 2848 deals (pipeline + won + lost), 24 vendedores  

---

## üìä ESTADO ATUAL (INVENT√ÅRIO)

### ‚úÖ Backend Existente (`simple_api.py` + m√≥dulos)

**Cloud Run:** Estrutura modular em `/cloud-run/app/`
```
app/
‚îú‚îÄ‚îÄ simple_api.py (API principal)
‚îî‚îÄ‚îÄ api/endpoints/
    ‚îú‚îÄ‚îÄ ai_analysis.py      # An√°lise com Gemini
    ‚îú‚îÄ‚îÄ insights.py         # Insights b√°sicos
    ‚îú‚îÄ‚îÄ insights_rag.py     # üî• RAG com Vector Search
    ‚îî‚îÄ‚îÄ performance.py      # Performance de vendedores
```

**Endpoints Ativos:**
- `/api/dashboard` - M√©tricas agregadas
- `/api/pipeline` - Pipeline ativo (filtrado por year/quarter/seller)
- `/api/closed/won` - Deals ganhos
- `/api/closed/lost` - Deals perdidos
- `/api/insights-rag` - **RAG: Busca sem√¢ntica + Gemini**
- `/api/performance/seller/{name}` - Performance individual

### ‚úÖ BigQuery Dataset: `sales_intelligence`

| Tabela | Tipo | Descri√ß√£o | Registros |
|--------|------|-----------|-----------|
| `pipeline` | TABLE | Deals ativos | ~400 |
| `closed_deals_won` | TABLE | Vit√≥rias | ~1200 |
| `closed_deals_lost` | TABLE | Perdas | ~1200 |
| `sales_specialist` | TABLE | Camada de an√°lise Sales Ops | ~400 |
| `deal_embeddings` | TABLE | **RAG unificado** (pipeline+won+lost) | **2848** |
| `ml_prioridade_deal_v2` | VIEW | Prioriza√ß√£o ML | - |
| `ml_proxima_acao_v2` | VIEW | Pr√≥xima a√ß√£o sugerida | - |

**Schema RAG (`deal_embeddings`):**
```json
{
  "deal_id": "STRING",
  "source": "STRING",  // pipeline | won | lost
  "Oportunidade": "STRING",
  "Vendedor": "STRING",
  "Conta": "STRING",
  "Gross": "FLOAT",
  "Net": "FLOAT",
  "Fiscal_Q": "STRING",
  "Produtos": "STRING",
  "Fase": "STRING",
  "content": "STRING",  // Texto rico para RAG
  "embedding": "REPEATED FLOAT"  // 768 dimens√µes
}
```

**Campo Chave:** `content` cont√©m texto estruturado como:
```
Deal GANHO: Oportunidade X | Cliente: Y | Vendedor: Z | 
Valor: R$ 500k | Ciclo: 45 dias | 
Fatores de Sucesso: Urg√™ncia fiscal, POC bem-sucedido | 
Causa Raiz: Budget aprovado Q4 | 
Li√ß√µes: Follow-up semanal com C-level manteve deal vivo
```

### ‚úÖ Frontend Atual (`public/index.html`)

**Se√ß√£o "Pauta Semanal" (linhas 2075-2180):**
- üü° **Implementa√ß√£o:** Frontend-only, sem backend dedicado
- Filtros: "Esta Semana" | "Pr√≥xima Semana" | "Todas"
- L√≥gica: Filtra `pipeline` por `Confiana >= 40%`
- Exibe: Cards por vendedor com deals priorit√°rios
- **PROBLEMA:** N√£o usa RAG, n√£o tem contexto hist√≥rico, n√£o gera perguntas

---

## üéØ OBJETIVO: NOVA ARQUITETURA

### 1Ô∏è‚É£ **PAUTA SEMANAL** (Refatorada)
**Objetivo:** Timeline de deals priorit√°rios + contexto RAG  
**HTML:** `/public/pautasemanal.html` (novo arquivo)  
**Backend:** `/api/weekly-agenda` (novo endpoint)

### 2Ô∏è‚É£ **APRESENTA√á√ÉO SEMANAL / WAR ROOM** (Nova Feature)
**Objetivo:** Dashboard executivo estilo "A Verdade Nua e Crua"  
**HTML:** `/public/apresentacao.html` (novo arquivo)  
**Backend:** `/api/war-room` (novo endpoint)

---

## üîß ARQUITETURA DETALHADA

### üèõÔ∏è CAMADA 1: BigQuery (Fonte de Verdade)

#### **Nova VIEW: `pauta_semanal_enriquecida`**
```sql
CREATE OR REPLACE VIEW `operaciones-br.sales_intelligence.pauta_semanal_enriquecida` AS
WITH pipeline_ativo AS (
  SELECT 
    p.*,
    ss.Status as Status_Especialista,
    ss.Comentario as Comentario_Especialista,
    ml_prior.prioridade as Prioridade_ML,
    ml_acao.proxima_acao as Proxima_Acao_ML,
    -- Calcular "semana no quarter"
    DATE_DIFF(CURRENT_DATE(), DATE_TRUNC(CURRENT_DATE(), QUARTER), WEEK) + 1 as Semana_Quarter
  FROM `operaciones-br.sales_intelligence.pipeline` p
  LEFT JOIN `operaciones-br.sales_intelligence.sales_specialist` ss
    ON p.Oportunidade = ss.Oportunidade
  LEFT JOIN `operaciones-br.sales_intelligence.ml_prioridade_deal_v2` ml_prior
    ON p.Oportunidade = ml_prior.opportunity_id
  LEFT JOIN `operaciones-br.sales_intelligence.ml_proxima_acao_v2` ml_acao
    ON p.Oportunidade = ml_acao.opportunity_id
),
deals_com_risco AS (
  SELECT *,
    -- Score de Risco (0-5)
    CAST(
      (CASE WHEN Atividades = 0 THEN 1 ELSE 0 END) +
      (CASE WHEN CAST(Dias_Funil AS INT64) > 90 THEN 1 ELSE 0 END) +
      (CASE WHEN Territorio = 'Incorreto' THEN 1 ELSE 0 END) +
      (CASE WHEN Confiana < 30 THEN 1 ELSE 0 END) +
      (CASE WHEN Status_Especialista = 'Commit' AND Forecast_SF != 'Committed' THEN 1 ELSE 0 END)
    AS INT64) as Risco_Score,
    -- Flags espec√≠ficas
    CASE 
      WHEN Atividades = 0 AND CAST(Dias_Funil AS INT64) > 90 THEN 'ZUMBI'
      WHEN Confiana >= 70 THEN 'CRITICO'
      WHEN Confiana >= 40 THEN 'ALTA_PRIORIDADE'
      ELSE 'MONITORAR'
    END as Categoria_Pauta
  FROM pipeline_ativo
)
SELECT * 
FROM deals_com_risco
WHERE Categoria_Pauta IN ('CRITICO', 'ALTA_PRIORIDADE', 'ZUMBI')
ORDER BY Risco_Score DESC, Gross DESC;
```

#### **Nova VIEW: `war_room_metrics`**
```sql
CREATE OR REPLACE VIEW `operaciones-br.sales_intelligence.war_room_metrics` AS
WITH quarter_atual AS (
  SELECT 
    CONCAT('FY', EXTRACT(YEAR FROM CURRENT_DATE()) - 2000, '-Q', EXTRACT(QUARTER FROM CURRENT_DATE())) as Fiscal_Q_Atual
),
metricas_por_vendedor AS (
  SELECT 
    Vendedor,
    -- Pipeline
    ROUND(SUM(CASE WHEN source = 'pipeline' THEN Gross ELSE 0 END), 2) as Pipeline_Gross,
    COUNT(CASE WHEN source = 'pipeline' THEN 1 END) as Pipeline_Deals,
    -- Fechado (Q atual)
    ROUND(SUM(CASE WHEN source = 'won' AND Fiscal_Q = (SELECT Fiscal_Q_Atual FROM quarter_atual) THEN Gross ELSE 0 END), 2) as Closed_Gross,
    COUNT(CASE WHEN source = 'won' AND Fiscal_Q = (SELECT Fiscal_Q_Atual FROM quarter_atual) THEN 1 END) as Closed_Deals,
    -- Higiene de Pipeline
    ROUND(
      100 * COUNT(CASE WHEN source = 'pipeline' AND (Atividades = 0 OR Territorio = 'Incorreto') THEN 1 END) / 
      NULLIF(COUNT(CASE WHEN source = 'pipeline' THEN 1 END), 0), 
      2
    ) as Percent_Pipeline_Podre,
    -- Zumbis
    COUNT(CASE WHEN source = 'pipeline' AND Atividades = 0 AND CAST(Dias_Funil AS INT64) > 90 THEN 1 END) as Deals_Zumbi
  FROM (
    -- Unificar pipeline + closed
    SELECT Vendedor, Gross, 'pipeline' as source, Fiscal_Q, Atividades, Territorio, Dias_Funil
    FROM `operaciones-br.sales_intelligence.pipeline`
    UNION ALL
    SELECT Vendedor, Gross, 'won' as source, Fiscal_Q, Atividades, NULL as Territorio, NULL as Dias_Funil
    FROM `operaciones-br.sales_intelligence.closed_deals_won`
  )
  GROUP BY Vendedor
)
SELECT 
  Vendedor,
  Pipeline_Gross,
  Closed_Gross,
  Closed_Gross + Pipeline_Gross as Total_Forecast,
  Pipeline_Deals,
  Closed_Deals,
  Percent_Pipeline_Podre,
  Deals_Zumbi,
  -- Nota de Higiene (A a F)
  CASE 
    WHEN Percent_Pipeline_Podre <= 10 THEN 'A'
    WHEN Percent_Pipeline_Podre <= 20 THEN 'B'
    WHEN Percent_Pipeline_Podre <= 35 THEN 'C'
    WHEN Percent_Pipeline_Podre <= 50 THEN 'D'
    ELSE 'F'
  END as Nota_Higiene
FROM metricas_por_vendedor
ORDER BY Total_Forecast DESC;
```

---

### üõ∞Ô∏è CAMADA 2: Backend API (FastAPI)

#### **Novo M√≥dulo: `/cloud-run/app/api/endpoints/weekly_agenda.py`**
```python
"""
Weekly Agenda Endpoint - Pauta Semanal Enriquecida com RAG
"""
from fastapi import APIRouter, Query
from google.cloud import bigquery
from typing import Optional, List, Dict, Any
import os

router = APIRouter()

PROJECT_ID = os.getenv("GCP_PROJECT", "operaciones-br")
DATASET_ID = "sales_intelligence"

def get_bq_client():
    return bigquery.Client(project=PROJECT_ID)

@router.get("/weekly-agenda")
async def get_weekly_agenda(
    seller: Optional[str] = Query(None, description="Filtrar por vendedor"),
    week_offset: int = Query(0, ge=-4, le=4, description="Offset de semanas (0=atual, 1=pr√≥xima, -1=anterior)")
):
    """
    Retorna pauta semanal enriquecida com:
    - Deals priorit√°rios da VIEW pauta_semanal_enriquecida
    - Contexto RAG de deals similares hist√≥ricos (won/lost)
    - Perguntas de sabatina geradas por l√≥gica
    """
    client = get_bq_client()
    
    # 1. Buscar deals da pauta
    where_clauses = []
    if seller:
        sellers = [s.strip() for s in seller.split(',')]
        if len(sellers) == 1:
            where_clauses.append(f"Vendedor = '{sellers[0]}'")
        else:
            where_clauses.append(f"Vendedor IN ('{\"', '\".join(sellers)}')")
    
    where_sql = "WHERE " + " AND ".join(where_clauses) if where_clauses else ""
    
    query_pauta = f"""
    SELECT * 
    FROM `{PROJECT_ID}.{DATASET_ID}.pauta_semanal_enriquecida`
    {where_sql}
    """
    
    deals = [dict(row) for row in client.query(query_pauta).result()]
    
    # 2. Para cada deal, enriquecer com contexto RAG
    for deal in deals:
        # Buscar deals similares usando RAG
        query_similar = f"""
        WITH target_embedding AS (
          SELECT embedding
          FROM `{PROJECT_ID}.{DATASET_ID}.deal_embeddings`
          WHERE Oportunidade = @oportunidade
          LIMIT 1
        )
        SELECT 
          de.deal_id,
          de.source,
          de.Oportunidade,
          de.Conta,
          de.Gross,
          de.content,
          -- Similaridade cosseno
          (
            SELECT SUM(a * b) / (SQRT(SUM(a * a)) * SQRT(SUM(b * b)))
            FROM UNNEST(de.embedding) a WITH OFFSET pos
            JOIN UNNEST((SELECT embedding FROM target_embedding)) b WITH OFFSET pos2
            ON pos = pos2
          ) as similarity
        FROM `{PROJECT_ID}.{DATASET_ID}.deal_embeddings` de
        WHERE de.source IN ('won', 'lost') 
          AND de.Vendedor = @vendedor
        ORDER BY similarity DESC
        LIMIT 5
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("oportunidade", "STRING", deal["Oportunidade"]),
                bigquery.ScalarQueryParameter("vendedor", "STRING", deal["Vendedor"])
            ]
        )
        
        similar_deals = [dict(row) for row in client.query(query_similar, job_config=job_config).result()]
        deal["similar_deals"] = similar_deals
        
        # 3. Gerar perguntas de sabatina
        deal["sabatina_questions"] = generate_sabatina_questions(deal)
    
    return {
        "timestamp": "2026-02-08T00:00:00Z",
        "total_deals": len(deals),
        "deals": deals
    }

def generate_sabatina_questions(deal: Dict[str, Any]) -> List[str]:
    """
    Gera perguntas baseadas em flags de risco.
    """
    questions = []
    
    # Regra 1: Atividades zeradas
    if deal.get("Atividades") == 0:
        questions.append("‚ùå Este deal est√° abandonado? Qual √© a data da pr√≥xima reuni√£o agendada?")
    
    # Regra 2: Zumbis
    if deal.get("Categoria_Pauta") == "ZUMBI":
        questions.append("üíÄ Deal > 90 dias sem atividade. Qual o plano para reviver ou matar este deal?")
    
    # Regra 3: Diverg√™ncia Especialista vs. SF
    if deal.get("Status_Especialista") == "Commit" and deal.get("Forecast_SF") != "Committed":
        questions.append("‚ö†Ô∏è Especialista diz 'Commit', voc√™ diz 'Pipeline'. Quem est√° certo? Por qu√™?")
    
    # Regra 4: Alta confian√ßa sem or√ßamento
    if deal.get("Confiana", 0) >= 70 and "SEM_ORCAMENTO" in (deal.get("Flags_de_Risco") or ""):
        questions.append("üí∞ Como garantimos fechamento sem or√ßamento confirmado? Quem assina o contrato?")
    
    # Regra 5: Deal > 500k estagnado
    if deal.get("Gross", 0) > 500000 and int(deal.get("Dias_Funil", 0)) > 180:
        questions.append("üìâ Deal de R$500k+ h√° 6+ meses. Qual o evento compelidor que for√ßa o cliente a comprar AGORA?")
    
    # Regra 6: Territ√≥rio incorreto
    if deal.get("Territorio") == "Incorreto":
        questions.append("üö´ Por que este deal ainda est√° no seu nome se √© de outro territ√≥rio?")
    
    return questions
```

#### **Novo M√≥dulo: `/cloud-run/app/api/endpoints/war_room.py`**
```python
"""
War Room Endpoint - Apresenta√ß√£o Semanal Executiva
"""
from fastapi import APIRouter, Query
from google.cloud import bigquery
from typing import Optional, Dict, Any, List
import google.generativeai as genai
import os
from datetime import datetime, date

router = APIRouter()

PROJECT_ID = os.getenv("GCP_PROJECT", "operaciones-br")
DATASET_ID = "sales_intelligence"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyBwgc9nHAtgUiabpGJDwrMBd3dJTBE5ee4")

genai.configure(api_key=GEMINI_API_KEY)

def get_bq_client():
    return bigquery.Client(project=PROJECT_ID)

def get_current_week_in_quarter() -> Dict[str, Any]:
    """
    Retorna metadados da semana atual dentro do quarter.
    Exemplo: Q1 2026, Semana 6 de 13
    """
    today = date.today()
    quarter = (today.month - 1) // 3 + 1
    year_short = today.year - 2000
    fiscal_q = f"FY{year_short}-Q{quarter}"
    
    # Calcular semana dentro do quarter
    quarter_start = date(today.year, (quarter - 1) * 3 + 1, 1)
    days_in_quarter = (today - quarter_start).days
    week_in_quarter = (days_in_quarter // 7) + 1
    
    return {
        "fiscal_q": fiscal_q,
        "quarter": quarter,
        "year": today.year,
        "week_in_quarter": week_in_quarter,
        "total_weeks_in_quarter": 13,  # ~13 semanas por quarter
        "current_date": today.isoformat()
    }

@router.get("/war-room")
async def get_war_room_report():
    """
    Gera relat√≥rio War Room com:
    1. Resumo Executivo (Fechado vs. Pipeline)
    2. M√©tricas por Vendedor (Higiene, Notas, Zumbis)
    3. Hit List de Oportunidades Cr√≠ticas com Perguntas de Sabatina
    """
    client = get_bq_client()
    week_info = get_current_week_in_quarter()
    
    # 1. Resumo Executivo
    query_summary = f"""
    WITH quarter_atual AS (
      SELECT '{week_info['fiscal_q']}' as Fiscal_Q_Atual
    )
    SELECT 
      ROUND(SUM(CASE WHEN source = 'won' AND Fiscal_Q = (SELECT Fiscal_Q_Atual FROM quarter_atual) THEN Gross ELSE 0 END), 2) as Closed_Gross,
      ROUND(SUM(CASE WHEN source = 'pipeline' THEN Gross ELSE 0 END), 2) as Pipeline_Gross,
      COUNT(CASE WHEN source = 'won' AND Fiscal_Q = (SELECT Fiscal_Q_Atual FROM quarter_atual) THEN 1 END) as Closed_Deals,
      COUNT(CASE WHEN source = 'pipeline' THEN 1 END) as Pipeline_Deals,
      COUNT(CASE WHEN source = 'pipeline' AND Atividades = 0 AND CAST(Dias_Funil AS INT64) > 90 THEN 1 END) as Total_Zumbis
    FROM (
      SELECT Gross, 'won' as source, Fiscal_Q, NULL as Atividades, NULL as Dias_Funil
      FROM `{PROJECT_ID}.{DATASET_ID}.closed_deals_won`
      UNION ALL
      SELECT Gross, 'pipeline' as source, Fiscal_Q, Atividades, Dias_Funil
      FROM `{PROJECT_ID}.{DATASET_ID}.pipeline`
    )
    """
    
    summary = dict(next(client.query(query_summary).result()))
    
    # 2. M√©tricas por Vendedor
    query_sellers = f"""
    SELECT * 
    FROM `{PROJECT_ID}.{DATASET_ID}.war_room_metrics`
    ORDER BY Total_Forecast DESC
    """
    
    sellers = [dict(row) for row in client.query(query_sellers).result()]
    
    # 3. Hit List (Top 20 deals cr√≠ticos)
    query_hitlist = f"""
    SELECT *
    FROM `{PROJECT_ID}.{DATASET_ID}.pauta_semanal_enriquecida`
    WHERE Categoria_Pauta IN ('CRITICO', 'ZUMBI')
    ORDER BY Risco_Score DESC, Gross DESC
    LIMIT 20
    """
    
    hitlist = [dict(row) for row in client.query(query_hitlist).result()]
    
    # 4. Para cada deal da hit list, gerar perguntas de sabatina
    for deal in hitlist:
        deal["sabatina_questions"] = generate_sabatina_questions(deal)
        # Calcular tags de risco
        deal["risk_tags"] = generate_risk_tags(deal)
    
    # 5. Gerar insights com Gemini
    ai_insights = generate_executive_insights(summary, sellers, hitlist)
    
    return {
        "timestamp": datetime.utcnow().isoformat(),
        "week_info": week_info,
        "executive_summary": summary,
        "sellers": sellers,
        "hit_list": hitlist,
        "ai_insights": ai_insights
    }

def generate_sabatina_questions(deal: Dict[str, Any]) -> List[str]:
    """Mesmo c√≥digo do weekly_agenda.py"""
    questions = []
    
    if deal.get("Atividades") == 0:
        questions.append("‚ùå Este deal est√° abandonado? Qual √© a data da pr√≥xima reuni√£o agendada?")
    
    if deal.get("Categoria_Pauta") == "ZUMBI":
        questions.append("üíÄ Deal > 90 dias sem atividade. Qual o plano para reviver ou matar este deal?")
    
    if deal.get("Status_Especialista") == "Commit" and deal.get("Forecast_SF") != "Committed":
        questions.append("‚ö†Ô∏è Especialista diz 'Commit', voc√™ diz 'Pipeline'. Quem est√° certo?")
    
    if deal.get("Confiana", 0) >= 70 and "SEM_ORCAMENTO" in (deal.get("Flags_de_Risco") or ""):
        questions.append("üí∞ Como garantimos fechamento sem or√ßamento confirmado?")
    
    if deal.get("Gross", 0) > 500000 and int(deal.get("Dias_Funil", 0)) > 180:
        questions.append("üìâ Qual o evento compelidor que for√ßa o cliente a comprar AGORA?")
    
    if deal.get("Territorio") == "Incorreto":
        questions.append("üö´ Por que este deal ainda est√° no seu nome?")
    
    return questions

def generate_risk_tags(deal: Dict[str, Any]) -> List[str]:
    """Gera tags visuais de risco"""
    tags = []
    
    if deal.get("Categoria_Pauta") == "ZUMBI":
        tags.append("üíÄ ZUMBI")
    if deal.get("Risco_Score", 0) >= 4:
        tags.append("üî¥ RISCO ALTO")
    if deal.get("Atividades") == 0:
        tags.append("‚è∏Ô∏è SEM ATIVIDADE")
    if deal.get("Territorio") == "Incorreto":
        tags.append("üö´ TERRIT√ìRIO ERRADO")
    if deal.get("Status_Especialista") == "Commit" and deal.get("Forecast_SF") != "Committed":
        tags.append("‚ö†Ô∏è DESALINHADO")
    
    return tags

def generate_executive_insights(summary: Dict, sellers: List[Dict], hitlist: List[Dict]) -> Dict[str, Any]:
    """
    Usa Gemini para gerar insights executivos baseados nos dados.
    """
    context = f"""
Voc√™ √© um VP de Sales Ops analisando a Revis√£o Semanal de Forecast.

DADOS DO QUARTER ATUAL:
- Fechado: R$ {summary['Closed_Gross']:,.2f} ({summary['Closed_Deals']} deals)
- Pipeline: R$ {summary['Pipeline_Gross']:,.2f} ({summary['Pipeline_Deals']} deals)
- Zumbis no Pipeline: {summary['Total_Zumbis']}

TOP 5 VENDEDORES (por forecast total):
{chr(10).join([f"- {s['Vendedor']}: R$ {s['Total_Forecast']:,.2f} | Nota Higiene: {s['Nota_Higiene']} | Zumbis: {s['Deals_Zumbi']}" for s in sellers[:5]])}

TOP 5 DEALS CR√çTICOS:
{chr(10).join([f"- {d['Oportunidade']} ({d['Vendedor']}) | R$ {d['Gross']:,.2f} | Risco: {d['Risco_Score']}/5 | Categoria: {d['Categoria_Pauta']}" for d in hitlist[:5]])}

INSTRU√á√ïES:
1. D√™ 3 PONTOS DE ATEN√á√ÉO para o CEO (riscos reais, sem enrola√ß√£o)
2. D√™ 2 VIT√ìRIAS DA SEMANA (se houver)
3. D√™ 3 A√á√ïES IMEDIATAS para corrigir problemas

Seja direto. Sem enfeites. Foco em n√∫meros e a√ß√µes.
"""
    
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(context)
        text = response.text if response else ""
    except Exception as e:
        text = f"Erro ao gerar insights: {str(e)}"
    
    return {
        "raw_text": text,
        "summary": summary,
        "top_sellers": sellers[:5],
        "critical_deals": hitlist[:5]
    }
```

#### **Registrar novos routers em `/cloud-run/app/simple_api.py`:**
```python
# Import modular endpoints
from api.endpoints.ai_analysis import router as ai_router
from api.endpoints.insights import router as insights_router
from api.endpoints.insights_rag import router as insights_rag_router
from api.endpoints.performance import router as performance_router
from api.endpoints.weekly_agenda import router as weekly_agenda_router  # NOVO
from api.endpoints.war_room import router as war_room_router  # NOVO

# Include modular routers
app.include_router(ai_router, prefix="/api", tags=["AI Analysis"])
app.include_router(insights_router, prefix="/api", tags=["Insights"])
app.include_router(insights_rag_router, prefix="/api", tags=["Insights RAG"])
app.include_router(performance_router, prefix="/api", tags=["Performance"])
app.include_router(weekly_agenda_router, prefix="/api", tags=["Weekly Agenda"])  # NOVO
app.include_router(war_room_router, prefix="/api", tags=["War Room"])  # NOVO
```

---

### üé® CAMADA 3: Frontend

#### **Novo Arquivo: `/public/pautasemanal.html`**
**Estrutura:**
- **Header:** Filtros (Vendedor, Semana, Quarter)
- **Cards de Resumo:** Deals Cr√≠ticos, Alta Prioridade, A√ß√µes Pendentes
- **Timeline por Vendedor:** Acorde√£o com lista de deals
  - Para cada deal:
    - **Badge de Risco:** Score 0-5 (cores: verde ‚Üí vermelho)
    - **Tags:** ZUMBI, SEM_ATIVIDADE, etc.
    - **Contexto RAG:** "Deals similares que este vendedor ganhou/perdeu"
    - **Bot√£o "Sabatina":** Expande perguntas geradas pela IA
- **Chamada API:** `GET /api/weekly-agenda?seller=Alex&week_offset=0`

#### **Novo Arquivo: `/public/apresentacao.html` (War Room)**
**Estrutura:**
- **Header:** Metadados da semana (Q1 2026, Semana 6/13)
- **Resumo Executivo (Cards):**
  - Fechado no Q: R$ X | Y deals
  - Pipeline: R$ Z | W deals
  - Risco Ponderado: R$ K
  - Zumbis: N deals
- **Navega√ß√£o Lateral:** Lista de Vendedores (com nota A-F)
- **Painel do Vendedor (ao clicar):**
  - **Card de Higiene:** 
    - Nota: A-F
    - % Pipeline Podre
    - Deals Zumbi
  - **Hit List (Tabela):**
    - Colunas: Conta | Oportunidade | Valor | Stage | Risco | Tags | **Perguntas**
    - Estilo: Deals com risco ‚â• 4 em vermelho, Zumbis com opacidade reduzida
  - **Insights IA:** Painel lateral com an√°lise do Gemini
- **Chamada API:** `GET /api/war-room`

#### **Modifica√ß√£o: `/public/index.html`**
**A√ß√£o:** Remover se√ß√£o "Pauta Semanal" (linhas 2075-2180) e adicionar link no sidebar:
```html
<div class="menu-item" onclick="navigateToPage('pautasemanal.html')" style="...">
  <svg class="icon"><use href="#icon-calendar"/></svg>
  Pauta Semanal
</div>
<div class="menu-item" onclick="navigateToPage('apresentacao.html')" style="...">
  <svg class="icon"><use href="#icon-target"/></svg>
  Apresenta√ß√£o Semanal
</div>
```

---

## üîó ORQUESTRA√á√ÉO E FLUXO DE DADOS

```mermaid
graph TD
    A[BigQuery: sales_intelligence] -->|Pipeline + Won + Lost| B[deal_embeddings]
    B -->|Vector Search| C[Vertex AI Text Embeddings]
    A -->|SQL Views| D[pauta_semanal_enriquecida]
    A -->|SQL Views| E[war_room_metrics]
    
    D -->|REST API| F[FastAPI: /api/weekly-agenda]
    E -->|REST API| G[FastAPI: /api/war-room]
    C -->|RAG Context| F
    C -->|RAG Context| G
    
    F -->|JSON Response| H[pautasemanal.html]
    G -->|JSON Response| I[apresentacao.html]
    
    J[Gemini 1.5 Flash] -->|Generate Insights| G
    J -->|Enrich Context| F
    
    K[User] -->|Click Sidebar| H
    K -->|Click Sidebar| I
    
    style B fill:#4A9EFF
    style C fill:#C0FF7D
    style J fill:#FF89FF
```

### **Fluxo t√≠pico - Pauta Semanal:**
1. **User** acessa `/pautasemanal.html`
2. **Frontend** chama `GET /api/weekly-agenda?seller=Alex&week_offset=0`
3. **Backend**:
   - Consulta VIEW `pauta_semanal_enriquecida`
   - Para cada deal, busca no RAG (`deal_embeddings`) deals similares hist√≥ricos
   - Gera perguntas de sabatina baseadas em regras
4. **Backend** retorna JSON com:
   ```json
   {
     "total_deals": 12,
     "deals": [
       {
         "Oportunidade": "Deal X",
         "Vendedor": "Alex",
         "Gross": 500000,
         "Risco_Score": 4,
         "Categoria_Pauta": "CRITICO",
         "similar_deals": [...],
         "sabatina_questions": [
           "‚ùå Este deal est√° abandonado?",
           "üí∞ Como garantimos fechamento sem or√ßamento?"
         ]
       }
     ]
   }
   ```
5. **Frontend** renderiza:
   - Cards de deals com badges de risco
   - Se√ß√£o "Contexto Hist√≥rico" (similar deals do RAG)
   - Bot√£o "Sabatina" que expande perguntas

### **Fluxo t√≠pico - War Room:**
1. **User** acessa `/apresentacao.html`
2. **Frontend** chama `GET /api/war-room`
3. **Backend**:
   - Calcula m√©tricas do quarter atual
   - Consulta VIEW `war_room_metrics` para vendedores
   - Busca top 20 deals cr√≠ticos
   - **Chama Gemini** para gerar insights executivos
4. **Backend** retorna JSON com:
   ```json
   {
     "week_info": {
       "fiscal_q": "FY26-Q1",
       "week_in_quarter": 6,
       "total_weeks_in_quarter": 13
     },
     "executive_summary": {
       "Closed_Gross": 2500000,
       "Pipeline_Gross": 5000000,
       "Total_Zumbis": 15
     },
     "sellers": [...],
     "hit_list": [...],
     "ai_insights": {
       "raw_text": "PONTOS DE ATEN√á√ÉO:\n1. 15 deals zumbis...",
       "top_sellers": [...],
       "critical_deals": [...]
     }
   }
   ```
5. **Frontend** renderiza:
   - Dashboard estilo "War Room" com cores de alerta
   - Abas por vendedor (navega√ß√£o lateral)
   - Tabela "Hit List" com perguntas de sabatina inline
   - Painel de insights da IA

---

## üöÄ DEPLOYMENT

### **1. BigQuery:**
```bash
# Criar VIEWs
bq query --use_legacy_sql=false < bigquery/create_view_pauta_semanal.sql
bq query --use_legacy_sql=false < bigquery/create_view_war_room_metrics.sql
```

### **2. Cloud Run (Backend):**
```bash
cd /workspaces/playbook/cloud-run
gcloud run deploy sales-intelligence-api \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --project operaciones-br \
  --set-env-vars GCP_PROJECT=operaciones-br,GEMINI_API_KEY=...
```

### **3. Frontend (Static Hosting):**
```bash
# Op√ß√£o 1: Firebase Hosting
firebase deploy --only hosting

# Op√ß√£o 2: Cloud Storage + Load Balancer
gsutil -m cp -r public/* gs://xertica-dashboard/
```

---

## üìä COMO O RAG POTENCIALIZA A SOLU√á√ÉO

### **Uso Estrat√©gico de `deal_embeddings`:**

1. **Contexto Hist√≥rico por Vendedor:**
   - "Deals similares que Alex ganhou no passado com mesmo perfil de cliente"
   - Permite gerente comparar: "Por que este deal est√° parado se voc√™ j√° fechou 3 iguais?"

2. **Padr√µes de Perdas:**
   - "3 deals similares perdidos pelo mesmo motivo: or√ßamento cortado em dezembro"
   - Recomenda√ß√£o: "Antecipar fechamento para evitar budget freeze"

3. **Li√ß√µes Aprendidas Automatizadas:**
   - Campo `content` em deals ganhos cont√©m "Fatores_Sucesso" e "Licoes_Aprendidas"
   - RAG retorna: "Deal similar ganho porque fizemos POC t√©cnico | Li√ß√£o: Envolver TI desde o in√≠cio"

4. **Inputs para Gemini:**
   - Gemini recebe contexto RAG + dados estruturados
   - Gera insights personalizados: "Este deal est√° 30 dias sem atividade. Hist√≥rico mostra que ap√≥s 40 dias, taxa de convers√£o cai 60%."

### **Queries RAG Implementadas:**

#### **Query 1: Similar Deals por Vendedor**
```sql
-- Busca vetorial: encontra deals hist√≥ricos similares ao deal atual
WITH target_embedding AS (
  SELECT embedding
  FROM `operaciones-br.sales_intelligence.deal_embeddings`
  WHERE Oportunidade = 'Deal X'
  LIMIT 1
)
SELECT 
  de.Oportunidade,
  de.source,  -- won | lost
  de.Gross,
  de.content,  -- Texto rico com li√ß√µes
  (
    SELECT SUM(a * b) / (SQRT(SUM(a * a)) * SQRT(SUM(b * b)))
    FROM UNNEST(de.embedding) a WITH OFFSET pos
    JOIN UNNEST((SELECT embedding FROM target_embedding)) b WITH OFFSET pos2
    ON pos = pos2
  ) as similarity
FROM `operaciones-br.sales_intelligence.deal_embeddings` de
WHERE de.source IN ('won', 'lost') 
  AND de.Vendedor = 'Alex'
ORDER BY similarity DESC
LIMIT 5
```

#### **Query 2: Padr√µes de Risco**
```sql
-- Encontra deals que entraram em "ZUMBI" e depois foram recuperados
SELECT 
  Oportunidade,
  Vendedor,
  Gross,
  content
FROM `operaciones-br.sales_intelligence.deal_embeddings`
WHERE source = 'won'
  AND LOWER(content) LIKE '%recuperado%'
  OR LOWER(content) LIKE '%reativado%'
ORDER BY Gross DESC
LIMIT 10
```

---

## üéØ DIFERENCIAIS DA ARQUITETURA

### ‚úÖ **1. Reutiliza√ß√£o de Componentes**
- RAG unificado (`deal_embeddings`) serve m√∫ltiplos contextos
- VIEWs BigQuery s√£o "fonte de verdade" √∫nica
- Endpoints FastAPI modulares (f√°cil manuten√ß√£o)

### ‚úÖ **2. Escalabilidade**
- BigQuery: Queries paralelas, cache autom√°tico
- Cloud Run: Auto-scaling baseado em tr√°fego
- Frontend: HTML est√°tico (CDN-friendly)

### ‚úÖ **3. Intelig√™ncia H√≠brida**
- **Regras de Neg√≥cio** (sabatina_questions): Determin√≠sticas, audit√°veis
- **RAG** (similar_deals): Contexto hist√≥rico rico
- **Gemini** (insights): Linguagem natural adaptativa

### ‚úÖ **4. "Verdade Nua e Crua"**
- Notas de Higiene A-F (n√£o h√° como esconder pipeline podre)
- Zumbis identificados automaticamente
- Perguntas de sabatina dif√≠ceis (for√ßam accountability)

### ‚úÖ **5. Acion√°vel**
- Cada insight tem "next step" claro
- Perguntas espec√≠ficas por deal (n√£o gen√©ricas)
- Timeline semanal (foco no que importa AGORA)

---

## üìà M√âTRICAS DE SUCESSO

| KPI | Baseline (Hoje) | Target (P√≥s-Implanta√ß√£o) |
|-----|-----------------|-------------------------|
| Tempo m√©dio de pauta semanal | 2h (manual) | 15 min (automatizado) |
| Deals zumbis identificados | ~30% n√£o detectados | 100% detectados |
| Ader√™ncia a perguntas de sabatina | 0% (n√£o existem) | 80% de ado√ß√£o |
| Insights acion√°veis por semana | ~5 (manual) | ~20 (IA-powered) |
| ROI: Tempo economizado Sales Ops | - | ~7h/semana (R$350/semana) |

---

## üõ†Ô∏è PR√ìXIMOS PASSOS (EXECU√á√ÉO)

### **Sprint 1: Backend (3 dias)**
- [ ] Criar VIEWs BigQuery (`pauta_semanal_enriquecida`, `war_room_metrics`)
- [ ] Implementar endpoint `/api/weekly-agenda`
- [ ] Implementar endpoint `/api/war-room`
- [ ] Testar queries RAG (similaridade)
- [ ] Deploy Cloud Run

### **Sprint 2: Frontend (3 dias)**
- [ ] Criar `/public/pautasemanal.html`
- [ ] Criar `/public/apresentacao.html`
- [ ] Remover se√ß√£o "Pauta Semanal" de `/public/index.html`
- [ ] Adicionar links no sidebar
- [ ] Testar integra√ß√µes API

### **Sprint 3: Refinamento + Go-Live (2 dias)**
- [ ] Ajustar prompts Gemini (qualidade insights)
- [ ] Adicionar loading states
- [ ] Otimizar queries (cache, √≠ndices)
- [ ] Documenta√ß√£o de uso
- [ ] Treinamento usu√°rios

---

## üß† CONSIDERA√á√ïES T√âCNICAS AVAN√áADAS

### **1. Cache e Performance**
- **BigQuery:** Ativar cache de 24h em VIEWs (gr√°tis)
- **Cloud Run:** Configurar `max-instances: 10` (evitar cold starts)
- **Frontend:** Service Worker para cache de assets

### **2. Custos**
- **RAG:** ~$0.02 por 1000 queries (text-embedding-004)
- **Gemini:** ~$0.50 por 1M tokens (flash = barato)
- **Cloud Run:** ~$0.10/dia (tr√°fego baixo)
- **Total estimado:** ~$20/m√™s

### **3. Seguran√ßa**
- **Cloud Run:** IAM roles (apenas operacoes-br)
- **BigQuery:** Row-level security (vendedor s√≥ v√™ seus deals)
- **Frontend:** Autentica√ß√£o via Firebase Auth (futuro)

### **4. Monitoramento**
- **Logs:** Cloud Logging (estruturados JSON)
- **M√©tricas:** Cloud Monitoring (lat√™ncia API)
- **Alertas:** Slack notifica√ß√µes para erros

---

## üìö REFER√äNCIAS E DOCUMENTA√á√ÉO

### **Arquivos Relacionados:**
- `/bigquery/setup_rag_embeddings.sql` - Setup do RAG
- `/cloud-run/app/api/endpoints/insights_rag.py` - Exemplo de busca vetorial
- `/public/index.html` - Dashboard principal (refer√™ncia UI)

### **Documenta√ß√£o Externa:**
- [BigQuery ML Text Embeddings](https://cloud.google.com/bigquery/docs/generate-text-embedding)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [Gemini API](https://ai.google.dev/gemini-api/docs)

---

## üö¶ STATUS: PRONTO PARA EXECU√á√ÉO

**Arquitetura aprovada?** ‚Üí Pr√≥ximo passo: Criar tasks no Jira/Linear  
**D√∫vidas t√©cnicas?** ‚Üí Revisar se√ß√£o de custos e performance  
**Go/No-Go?** ‚Üí Sprint 1 pode come√ßar AGORA  

---

**√öltima atualiza√ß√£o:** 2026-02-08  
**Autor:** GitHub Copilot (Claude Sonnet 4.5)  
**Reviewer:** Time de Sales Ops Xertica.ai
